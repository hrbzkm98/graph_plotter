{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from ndmg.stats import qa_graphs as qg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "\n",
    "def loadGraphs(filenames, verb=False):\n",
    "    \"\"\"\n",
    "    Given a list of files, returns a dictionary of graphs\n",
    "    Required parameters:\n",
    "        filenames:\n",
    "            - List of filenames for graphs\n",
    "    Optional parameters:\n",
    "        verb:\n",
    "            - Toggles verbose output statements\n",
    "    \"\"\"\n",
    "    #  Initializes empty dictionary\n",
    "    if type(filenames) is not list:\n",
    "        filenames = [filenames]\n",
    "    gstruct = OrderedDict()\n",
    "    for idx, files in enumerate(filenames):\n",
    "        if verb:\n",
    "            print(\"Loading: \" + files)\n",
    "        #  Adds graphs to dictionary with key being filename\n",
    "        fname = os.path.basename(files)\n",
    "        try:\n",
    "            gstruct[fname] = nx.read_graphml(files)\n",
    "        except:\n",
    "            gstruct[fname] = nx.read_gpickle(files)\n",
    "    return gstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from itertools import product\n",
    "from plotly.graph_objs import *\n",
    "from plotly import tools\n",
    "\n",
    "\n",
    "def plot_heatmap(dats, name=None, ylab=None, xlab=None, scale=False,\n",
    "                 scaletit=''):\n",
    "    data = [\n",
    "            Heatmap(\n",
    "                    z=dats,\n",
    "                    name=name,\n",
    "                    showscale=scale,\n",
    "                    colorscale='Reds',\n",
    "                    colorbar=dict(title=scaletit)\n",
    "                   )\n",
    "           ]\n",
    "    layout = std_layout(name, ylab, xlab)\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_degrees(dats, name=None, ylab=None, xlab=None, hemi=True):\n",
    "    data = list()\n",
    "    if hemi:\n",
    "        main = dats['ipso_deg']\n",
    "        contra = dats['contra_deg']\n",
    "    else:\n",
    "        main = dats['total_deg']\n",
    "    al = (4.0/len(main.keys()))\n",
    "\n",
    "    for key in main.keys():\n",
    "        lgth = len(main[key])\n",
    "        data += [\n",
    "                 Scatter(\n",
    "                         x=np.linspace(1, lgth, lgth),\n",
    "                         y=main[key],\n",
    "                         line=Line(\n",
    "                                   color='rgba(0,0,0,%1.2f)' % al\n",
    "                                  ),\n",
    "                         hoverinfo='x',\n",
    "                         name=name,\n",
    "                        )\n",
    "                ]\n",
    "        if hemi:\n",
    "            data += [\n",
    "                     Scatter(\n",
    "                             x=np.linspace(1, lgth, lgth),\n",
    "                             y=contra[key],\n",
    "                             line=Line(\n",
    "                                       color='rgba(0.11,0.62,0.47,%1.2f)' % al\n",
    "                                      ),\n",
    "                             hoverinfo='x',\n",
    "                             name=name,\n",
    "                            )\n",
    "                    ]\n",
    "    layout = std_layout(name, ylab, xlab)\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_series(dats, name=None, ylab=None, xlab=None, sort=False):\n",
    "    data = list()\n",
    "    for idx, ys in enumerate(dats):\n",
    "        if sort:\n",
    "            ys = np.sort(ys)\n",
    "        data += [\n",
    "                 Scatter(\n",
    "                         x=np.linspace(1, len(ys), len(ys)),\n",
    "                         y=ys,\n",
    "                         line=Line(\n",
    "                                   color='rgba(0,0,0,%1.2f)' % (4.0/len(dats))\n",
    "                                  ),\n",
    "                         hoverinfo='x',\n",
    "                         name=name,\n",
    "                        )\n",
    "                ]\n",
    "    layout = std_layout(name, ylab, xlab)\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_density(xs, ys, name=None, ylab=None, xlab=None):\n",
    "    data = list()\n",
    "    for idx, x in enumerate(xs):\n",
    "        data += [\n",
    "                 Scatter(\n",
    "                         x=xs[idx],\n",
    "                         y=ys[idx],\n",
    "                         line=Line(\n",
    "                                   color='rgba(0,0,0,%1.2f)' % (4.0/len(ys))\n",
    "                                  ),\n",
    "                         hoverinfo='x',\n",
    "                         name=name,\n",
    "                        )\n",
    "                ]\n",
    "    layout = std_layout(name, ylab, xlab)\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_rugdensity(series, name=None, ylab=None, xlab=None):\n",
    "    if len(series) > 1:\n",
    "        dens = gaussian_kde(series)\n",
    "        x = np.linspace(np.min(series), np.max(series), 100)\n",
    "        y = dens.evaluate(x)*np.max(series)\n",
    "\n",
    "        d_rug = Scatter(\n",
    "                    x=series,\n",
    "                    y=[0]*len(series),\n",
    "                    mode='markers',\n",
    "                    marker=Marker(\n",
    "                             color='rgba(0,0,0,0.9)',\n",
    "                             symbol='line-ns-open',\n",
    "                             size=10,\n",
    "                             opacity=0.5\n",
    "                           ),\n",
    "                    name=name\n",
    "              )\n",
    "    else:\n",
    "        x = 0\n",
    "        y = series\n",
    "\n",
    "    d_dens = Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                line=Line(\n",
    "                       color='rgba(0,0,0,0.9)'\n",
    "                     ),\n",
    "                hoverinfo='x',\n",
    "                name=name,\n",
    "           )\n",
    "    if len(series) > 1:\n",
    "        data = [d_dens, d_rug]\n",
    "    else:\n",
    "        data = [d_dens]\n",
    "    layout = std_layout(name, ylab, xlab)\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def std_layout(name=None, ylab=None, xlab=None):\n",
    "    return Layout(\n",
    "            title=name,\n",
    "            showlegend=False,\n",
    "            xaxis={'nticks': 5,\n",
    "                   'title': xlab},\n",
    "            yaxis={'nticks': 3,\n",
    "                   'title': ylab}\n",
    "          )\n",
    "\n",
    "\n",
    "def fig_to_trace(fig):\n",
    "    data = fig['data']\n",
    "    for item in data:\n",
    "        item.pop('xaxis', None)\n",
    "        item.pop('yaxis', None)\n",
    "    return data\n",
    "\n",
    "\n",
    "def traces_to_panels(traces, names=[], ylabs=None, xlabs=None):\n",
    "    r, c, locs = panel_arrangement(len(traces))\n",
    "    multi = tools.make_subplots(rows=r, cols=c, subplot_titles=names)\n",
    "    for idx, loc in enumerate(locs):\n",
    "        if idx < len(traces):\n",
    "            for component in traces[idx]:\n",
    "                multi.append_trace(component, *loc)\n",
    "        else:\n",
    "            multi = panel_invisible(multi, idx+1)\n",
    "    multi.layout['showlegend'] = False\n",
    "    return multi\n",
    "\n",
    "\n",
    "def panel_arrangement(num):\n",
    "    dims = list()\n",
    "    count = 0\n",
    "    while len(dims) == 0:\n",
    "        dims = list(factors(num+count))\n",
    "        count += 1\n",
    "\n",
    "    if len(dims) == 1:\n",
    "        row = col = dims[0]\n",
    "    else:\n",
    "        row = dims[0]\n",
    "        col = dims[-1]\n",
    "\n",
    "    locations = [(a+1, b+1) for a, b in product(range(row), range(col))]\n",
    "    return row, col, locations\n",
    "\n",
    "\n",
    "def panel_invisible(plot, idx):\n",
    "    for c in ['x', 'y']:\n",
    "        axe = c+'axis'+str(idx)\n",
    "        plot.layout[axe]['showgrid'] = False\n",
    "        plot.layout[axe]['zeroline'] = False\n",
    "        plot.layout[axe]['showline'] = False\n",
    "        plot.layout[axe]['showticklabels'] = False\n",
    "    return plot\n",
    "\n",
    "\n",
    "def rand_jitter(arr):\n",
    "    stdev = .03*(max(arr)-min(arr)+2)\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "\n",
    "\n",
    "def factors(N):\n",
    "    return set([item for subitem in\n",
    "                [(i, N//i) for i in range(1, int(N**0.5) + 1)\n",
    "                 if N % i == 0 and i > 1] for item in subitem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = ['graph.graphml','graph_1.gpickle']\n",
    "outdir = \"/home/student/Desktop/research/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('graph.graphml',\n",
       "              <networkx.classes.graph.Graph at 0x7f3b351783d0>),\n",
       "             ('graph_1.gpickle',\n",
       "              <networkx.classes.graph.Graph at 0x7f3b35178450>)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = loadGraphs(fs, verb=False)\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binGraphs(graphs, thr=0.1):\n",
    "    \"\"\"\n",
    "    Binarizes a set of graphs given a threshold.\n",
    "    Required Parameters:\n",
    "        graphs:\n",
    "            - a list of graphs.\n",
    "        thr:\n",
    "            - the threshold below which edges will be assumed disconnected.\n",
    "              .1 is chosen as default according to discriminability results.\n",
    "    \"\"\"\n",
    "    binGraphs = {}\n",
    "    for subj, graph in graphs.iteritems():\n",
    "        bin_graph = nx.Graph()\n",
    "        for (u, v, d) in graph.edges(data=True):\n",
    "            if d['weight'] > thr:\n",
    "                bin_graph.add_edge(u, v, weight=1)\n",
    "        binGraphs[subj] = bin_graph\n",
    "    return binGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(data, nbins=500, rng=None):\n",
    "    \"\"\"\n",
    "    Computes density for metrics which return vectors\n",
    "    Required parameters:\n",
    "        data:\n",
    "            - Dictionary of the vectors of data\n",
    "    \"\"\"\n",
    "    density = OrderedDict()\n",
    "    xs = OrderedDict()\n",
    "    for subj in data:\n",
    "        hist = np.histogram(data[subj], nbins)\n",
    "        hist = np.max(hist[0])\n",
    "        dens = gaussian_kde(data[subj])\n",
    "        if rng is not None:\n",
    "            xs[subj] = np.linspace(rng[0], rng[1], nbins)\n",
    "        else:\n",
    "            xs[subj] = np.linspace(0, np.max(data[subj]), nbins)\n",
    "        density[subj] = dens.evaluate(xs[subj])*np.max(data[subj]*hist)\n",
    "    return {\"xs\": xs, \"pdfs\": density}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality='dwi'\n",
    "if modality == 'func':\n",
    "    graphs = binGraphs(gr)\n",
    "else:\n",
    "    graphs = gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nx.number_of_nodes(graphs.values()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  Number of non-zero edges (i.e. binary edge count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnz = OrderedDict((subj, len(nx.edges(graphs[subj]))) for subj in graphs)\n",
    "# write(outdir, 'number_non_zeros', nnz, atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of creating a seperate pickled file, just store it in a dictionary.\n",
    "statsDict = {'number_non_zeros': nnz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: NNZ\n",
      "Sample Mean: 1337.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Computing: NNZ\")\n",
    "print(\"Sample Mean: %.2f\" % np.mean(nnz.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan Statistic-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_statistic(mygs, i):\n",
    "    \"\"\"\n",
    "    Computes scan statistic-i on a set of graphs\n",
    "    Required Parameters:\n",
    "        mygs:\n",
    "            - Dictionary of graphs\n",
    "        i:\n",
    "            - which scan statistic to compute\n",
    "    \"\"\"\n",
    "    ss = OrderedDict()\n",
    "    for key in mygs.keys():\n",
    "        g = mygs[key]\n",
    "        tmp = np.array(())\n",
    "        for n in g.nodes():\n",
    "            sg = nx.ego_graph(g, n, radius=i)\n",
    "            tmp = np.append(tmp, np.sum([sg.get_edge_data(e[0], e[1])['weight']\n",
    "                            for e in sg.edges()]))\n",
    "        ss[key] = tmp\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_means(data):\n",
    "    print(\"Subject Means: \" + \", \".join([\"%.2f\" % np.mean(data[key]) \n",
    "                                         for key in data.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 398574.53, 249819.52\n"
     ]
    }
   ],
   "source": [
    "temp_ss1 = scan_statistic(graphs, 1)\n",
    "ss1 = temp_ss1\n",
    "# write(outdir, 'locality_statistic', ss1, atlas)\n",
    "statsDict['locality_statistic'] = ss1\n",
    "print(\"Computing: Max Local Statistic Sequence\")\n",
    "show_means(temp_ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankGraphs(graphs):\n",
    "    \"\"\"\n",
    "    Ranks the edges in each element of a list of graphs.\n",
    "    Required Parameters:\n",
    "        graphs:\n",
    "            - a list of graphs.\n",
    "    \"\"\"\n",
    "    rankGraphs = {}\n",
    "    for subj, graph in graphs.iteritems():\n",
    "        rgraph = nx.Graph()\n",
    "        edge_ar = np.asarray([x[2]['weight'] for x in graph.edges(data=True)])\n",
    "        rank_edge = rankdata(edge_ar)  # rank the edges\n",
    "        for ((u, v, d), rank) in zip(graph.edges(data=True), rank_edge):\n",
    "            rgraph.add_edge(u, v, weight=rank)\n",
    "        rankGraphs[subj] = rgraph\n",
    "    return rankGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == 'func':\n",
    "    graphs = rankGraphs(gr)\n",
    "    wt_args = {'weight': 'weight'}\n",
    "else:\n",
    "    wt_args = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Clustering Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.65, 0.65\n"
     ]
    }
   ],
   "source": [
    "temp_cc = OrderedDict((subj, nx.clustering(graphs[subj],\n",
    "                                           **wt_args).values()) \n",
    "                      for subj in graphs)\n",
    "ccoefs = temp_cc\n",
    "# write(outdir, 'clustering_coefficients', ccoefs, atlas)\n",
    "statsDict['clustering_coefficients'] = ccoefs\n",
    "print(\"Computing: Clustering Coefficient Sequence\")\n",
    "show_means(temp_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Degree sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_deg = OrderedDict((subj, np.array(nx.degree(graphs[subj],\n",
    "                                                  **wt_args).values()))\n",
    "                        for subj in graphs)\n",
    "ipso_deg = OrderedDict()\n",
    "contra_deg = OrderedDict()\n",
    "for subj in graphs:  # TODO GK: remove forloop and use comprehension maybe?\n",
    "    g = graphs[subj]\n",
    "    N = len(g.nodes())\n",
    "    LLnodes = g.nodes()[0:N/2]  # TODO GK: don't assume hemispheres\n",
    "    LL = g.subgraph(LLnodes)\n",
    "    LLdegs = [LL.degree(**wt_args)[n] for n in LLnodes]\n",
    "\n",
    "    RRnodes = g.nodes()[N/2:N]  # TODO GK: don't assume hemispheres\n",
    "    RR = g.subgraph(RRnodes)\n",
    "    RRdegs = [RR.degree(**wt_args)[n] for n in RRnodes]\n",
    "\n",
    "    LRnodes = g.nodes()\n",
    "    ipso_list = LLdegs + RRdegs\n",
    "    degs = [g.degree(**wt_args)[n] for n in LRnodes]\n",
    "    contra_deg[subj] = [a_i - b_i for a_i, b_i in zip(degs, ipso_list)]\n",
    "    ipso_deg[subj] = ipso_list\n",
    "# import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Degree Sequence\n",
      "Subject Means: 26.47, 21.71\n"
     ]
    }
   ],
   "source": [
    "deg = {'total_deg': total_deg,\n",
    "       'ipso_deg': ipso_deg,\n",
    "       'contra_deg': contra_deg}\n",
    "print(\"Computing: Degree Sequence\")\n",
    "# write(outdir, 'degree_distribution', deg, atlas)\n",
    "statsDict['degree_distribution'] = deg\n",
    "show_means(total_deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Edge Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 1042.34, 1092.18\n"
     ]
    }
   ],
   "source": [
    "if modality == 'dwi':\n",
    "    print(\"Computing: Edge Weight Sequence\")\n",
    "    temp_ew = OrderedDict((s, [graphs[s].get_edge_data(e[0], e[1])['weight'] \n",
    "                               for e in graphs[s].edges()]) for s in graphs)\n",
    "    ew = temp_ew\n",
    "    # write(outdir, 'edge_weight', ew, atlas)\n",
    "    statsDict['edge_weight'] = ew\n",
    "    show_means(temp_ew)\n",
    "else:\n",
    "    temp_pl = OrderedDict()\n",
    "    print(\"Computing: Path Length Sequence\")\n",
    "    nxappl = nx.all_pairs_dijkstra_path_length\n",
    "    for s in graphs:\n",
    "        apd = nxappl(graphs[s])\n",
    "        # iterate over the nodes to find the average distance to each node\n",
    "        avg_path = [np.nanmean(v.values()) for k, v in apd.iteritems()]\n",
    "        temp_pl[s] = np.array(avg_path)\n",
    "    pl = temp_pl\n",
    "    # write(outdir, 'path_length', pl, atlas)\n",
    "    statsDict['path_length'] = pl\n",
    "    show_means(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigen Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Eigen Value Sequence\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing: Eigen Value Sequence\")\n",
    "laplac = OrderedDict((subj, nx.normalized_laplacian_matrix(graphs[subj])) \n",
    "                     for subj in graphs)\n",
    "eigs = OrderedDict((subj, np.sort(np.linalg.eigvals(laplac[subj].A))[::-1]) \n",
    "                   for subj in graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write(outdir, 'eigen_sequence', eigs, atlas)\n",
    "statsDict['eigen_sequence'] = eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject Maxes: 1.43, 1.45\n"
     ]
    }
   ],
   "source": [
    "print(\"Subject Maxes: \" + \", \".join([\"%.2f\" % np.max(eigs[key]) \n",
    "                                     for key in eigs.keys()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Betweenness Centrality Sequence\n",
      "Subject Means: 0.01, 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing: Betweenness Centrality Sequence\")\n",
    "nxbc = nx.algorithms.betweenness_centrality  # For PEP8 line length...\n",
    "temp_bc = OrderedDict((subj, nxbc(graphs[subj], **wt_args).values())\n",
    "                      for subj in graphs)\n",
    "centrality = temp_bc\n",
    "# write(outdir, 'betweenness_centrality', centrality, atlas)\n",
    "statsDict['betweenness_centrality'] = centrality\n",
    "show_means(temp_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: Mean Connectome\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing: Mean Connectome\")\n",
    "nxnp = nx.to_numpy_matrix\n",
    "adj = OrderedDict((subj, nxnp(graph, nodelist=sorted(graph.nodes())))\n",
    "                  for subj, graph in graphs.iteritems())\n",
    "mat = np.zeros(adj.values()[0].shape)\n",
    "for subj in adj:\n",
    "    mat += adj[subj]\n",
    "mat = mat/len(adj.keys())\n",
    "# write(outdir, 'study_mean_connectome', mat, atlas)\n",
    "statsDict['study_mean_connectome'] = mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['degree_distribution',\n",
       " 'betweenness_centrality',\n",
       " 'locality_statistic',\n",
       " 'eigen_sequence',\n",
       " 'number_non_zeros',\n",
       " 'clustering_coefficients',\n",
       " 'edge_weight',\n",
       " 'study_mean_connectome']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(statsDict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm if above code produces the same output as compute_metrics() in ndmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: NNZ\n",
      "Sample Mean: 1337.00\n",
      "Computing: Degree Sequence\n",
      "Subject Means: 26.47, 21.71\n",
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 1042.34, 1092.18\n",
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.65, 0.65\n",
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 398574.53, 249819.52\n",
      "Computing: Eigen Value Sequence\n",
      "Subject Maxes: 1.43, 1.45\n",
      "Computing: Betweenness Centrality Sequence\n",
      "Subject Means: 0.01, 0.01\n",
      "Computing: Mean Connectome\n"
     ]
    }
   ],
   "source": [
    "qg.compute_metrics(fs, outdir, atlas = \"atlas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['betweenness_centrality',\n",
       " 'clustering_coefficients',\n",
       " 'degree_distribution',\n",
       " 'edge_weight',\n",
       " 'eigen_sequence',\n",
       " 'locality_statistic',\n",
       " 'number_non_zeros',\n",
       " 'study_mean_connectome']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictKeys = list(statsDict.keys())\n",
    "dictKeys = sorted(dictKeys, key = str)\n",
    "dictKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == 'dwi':\n",
    "    modtit = \"DWI\"\n",
    "    order = [0, 1, 2, 5, 4, 3, 6, 7]\n",
    "    dictKeys = [dictKeys[o] for o in order]\n",
    "    labs = ['Betweenness Centrality', 'Clustering Coefficient', 'Degree',\n",
    "            'Locality Statistic-1', 'Eigenvalue', 'Edge Weight',\n",
    "            'Number of Non-zeros', 'Mean Connectome']\n",
    "else:\n",
    "    modtit = \"fMRI\"\n",
    "    order = [0, 1, 2, 6, 4, 3, 5, 7]\n",
    "    dictKeys = [dictKeys[o] for o in order]\n",
    "    labs = ['Betweenness Centrality', 'Clustering Coefficient', 'Degree',\n",
    "            'Average Path Length', 'Locality Statistic-1', 'Eigenvalue',\n",
    "            'Number of Non-zeros', 'Mean Connectome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_panel_plot(statsDict, outf, dataset=None, atlas=None, minimal=True, \n",
    "                    log=True, hemispheres=True, modality='dwi'):\n",
    "    \n",
    "    dictKeys = list(statsDict.keys())\n",
    "    dictKeys = sorted(dictKeys, key = str)\n",
    "    \n",
    "    if modality == 'dwi':\n",
    "        modtit = \"DWI\"\n",
    "        order = [0, 1, 2, 5, 4, 3, 6, 7]\n",
    "        dictKeys = [dictKeys[o] for o in order]\n",
    "        labs = ['Betweenness Centrality', 'Clustering Coefficient', 'Degree',\n",
    "                'Locality Statistic-1', 'Eigenvalue', 'Edge Weight',\n",
    "                'Number of Non-zeros', 'Mean Connectome']\n",
    "        \n",
    "    else:\n",
    "        modtit = \"fMRI\"\n",
    "        order = [0, 1, 2, 6, 4, 3, 5, 7]\n",
    "        dictKeys = [dictKeys[o] for o in order]\n",
    "        labs = ['Betweenness Centrality', 'Clustering Coefficient', 'Degree',\n",
    "                'Average Path Length', 'Locality Statistic-1', 'Eigenvalue',\n",
    "                'Number of Non-zeros', 'Mean Connectome']\n",
    "    traces = list(())\n",
    "    \n",
    "    for idx, curr in enumerate(dictKeys):\n",
    "        dat = statsDict[dictKeys[idx]]\n",
    "        if dictKeys[idx] == 'number_non_zeros':\n",
    "            fig = plot_rugdensity(dat.values())\n",
    "        elif dictKeys[idx] == 'edge_weight':\n",
    "            edges = np.max([len(dat[i]) for i in dat.keys()])\n",
    "            fig = plot_series(dat.values(), sort=True)\n",
    "        elif dictKeys[idx] == 'degree_distribution':\n",
    "            fig = plot_degrees(dat, hemi=hemispheres)\n",
    "            if hemispheres:\n",
    "                maxdat = np.max([np.max(dat[key][k]) \n",
    "                                 for key in dat.keys()\n",
    "                                 for k in dat[key]])\n",
    "                anno = [dict(x=dims/3,\n",
    "                             y=4*float(maxdat/7),\n",
    "                             xref='x3',\n",
    "                             yref='y3',\n",
    "                             text='ipsilateral',\n",
    "                             showarrow=False,\n",
    "                             font=dict(color='rgba(0.0,0.0,0.0,0.6)',\n",
    "                                       size=14)),\n",
    "                        dict(x=dims/3,\n",
    "                             y=3.7*float(maxdat/7),\n",
    "                             xref='x3',\n",
    "                             yref='y3',\n",
    "                             text='contralateral',\n",
    "                             showarrow=False,\n",
    "                             font=dict(color='rgba(0.11,0.62,0.47,0.6)',\n",
    "                                       size=14))]\n",
    "        elif dictKeys[idx] == 'study_mean_connectome':\n",
    "            if log:\n",
    "                dat = np.log10(dat+1)\n",
    "            fig = plot_heatmap(dat, name=labs[idx])\n",
    "        else:\n",
    "            dims = len(dat.values()[0])\n",
    "            fig = plot_series(dat.values())\n",
    "        traces += [fig_to_trace(fig)]\n",
    "\n",
    "    multi = traces_to_panels(traces)\n",
    "    for idx, curr, in enumerate(dictKeys):\n",
    "        key = 'axis%d' % (idx+1)\n",
    "        d = multi.layout['x'+key]['domain']\n",
    "        multi.layout['x'+key]['domain'] = [d[0], d[1]-0.0125]\n",
    "        multi.layout['x'+key]['zeroline'] = False\n",
    "        multi.layout['y'+key]['zeroline'] = False\n",
    "        multi.layout['y'+key]['title'] = ''\n",
    "        multi.layout['x'+key]['title'] = 'Node'\n",
    "        multi.layout['x'+key]['nticks'] = 3\n",
    "        multi.layout['y'+key]['nticks'] = 3\n",
    "        if (idx in [0, 1, 2, 3, 4, 5] and modality == 'func') or (idx in [0, 1, 2, 3, 4, 5] and modality == 'dwi'):\n",
    "            multi.layout['x'+key]['range'] = [1, dims]\n",
    "            multi.layout['x'+key]['tickvals'] = [1, dims/2, dims]\n",
    "            if idx in [2]:\n",
    "                if hemispheres:\n",
    "                    multi.layout['annotations'] = anno\n",
    "            elif log:\n",
    "                multi.layout['y'+key]['type'] = 'log'\n",
    "                multi.layout['y'+key]['title'] += 'log'\n",
    "        if idx in [5] and modality == 'dwi':\n",
    "            multi.layout['x'+key]['range'] = [1, edges]\n",
    "            multi.layout['x'+key]['tickvals'] = [1, edges/2, edges]\n",
    "            multi.layout['x'+key]['title'] = 'Edge'\n",
    "        if (idx in [4] and modality == 'dwi') or (idx in [5] and modality == 'func'):\n",
    "            multi.layout['x'+key]['range'] = [1, dims]\n",
    "            multi.layout['x'+key]['tickvals'] = [1, dims/2, dims]\n",
    "            multi.layout['x'+key]['title'] = 'Dimension'\n",
    "        multi.layout['y'+key]['title'] += labs[idx]\n",
    "        if (idx in [6]):\n",
    "            multi.layout['y'+key]['title'] = 'Relative Probability'\n",
    "            multi.layout['x'+key]['title'] = labs[idx]\n",
    "        if idx in [7]:\n",
    "            multi.layout['y'+key]['title'] = None\n",
    "            multi.layout['x'+key]['title'] = labs[idx]\n",
    "            multi.layout['y'+key]['autorange'] = 'reversed'\n",
    "            multi.layout['x'+key]['tickvals'] = [0, dims/2-1, dims-1]\n",
    "            multi.layout['y'+key]['tickvals'] = [0, dims/2-1, dims-1]\n",
    "            multi.layout['x'+key]['ticktext'] = [1, dims/2, dims]\n",
    "            multi.layout['y'+key]['ticktext'] = [1, dims/2, dims]\n",
    "            if log:\n",
    "                multi.layout['x'+key]['title'] += ' (log10)'\n",
    "    if dataset is not None and atlas is not None:\n",
    "        if atlas == 'desikan':\n",
    "            atlas = atlas.capitalize()\n",
    "        tit = \"{} Dataset ({} parcellation), {} Group Analysis\".format(dataset,\n",
    "                atlas, modtit)\n",
    "    else:\n",
    "        tit = \"{} Group Analysis\".format(modtit)\n",
    "    multi.layout['title'] = tit\n",
    "    # iplot(multi, validate=False)\n",
    "\n",
    "    if minimal:\n",
    "        locs = [idx for idx, d in enumerate(multi.data) if d['yaxis'] == 'y8']\n",
    "        for l in locs:\n",
    "            multi.data[l] = {}\n",
    "        multi.layout['x'+key]['title'] = ''\n",
    "        multi.layout['y'+key]['title'] = ''\n",
    "        multi = panel_invisible(multi, 8)\n",
    "\n",
    "    plot(multi, validate=False, filename=outf+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]  [ (1,4) x4,y4 ]\n",
      "[ (2,1) x5,y5 ]  [ (2,2) x6,y6 ]  [ (2,3) x7,y7 ]  [ (2,4) x8,y8 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_panel_plot(statsDict, outf = \"plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the output is the same as ndmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ndmg.stats import qa_graphs_plotting as qgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]  [ (1,4) x4,y4 ]\n",
      "[ (2,1) x5,y5 ]  [ (2,2) x6,y6 ]  [ (2,3) x7,y7 ]  [ (2,4) x8,y8 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qgp.make_panel_plot(basepath = outdir, outf = \"plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
